{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d9051b-c839-4f04-b721-b2437c7cf452",
   "metadata": {},
   "source": [
    "<a id='tablecontents'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3de91-878c-45e4-89b4-eb9b7ee73bae",
   "metadata": {},
   "source": [
    "# PySpark for Machine Learning - Foundations\n",
    "<h5>2023, Andrea Paviglianiti</h5>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b067a6-4e60-498d-a8be-2881b2fb3da3",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "\n",
    "- [Set Spark Environment](#section1)\n",
    "- [Linear Regression](#section2)\n",
    "    - [Import Modules](#s1p1)\n",
    "    - [ML from .txt data](#s1p2)\n",
    "    - [ML from .csv data](#s1p3)\n",
    "    - [Performance Evaluation](#s1p4)\n",
    "    - [Save predictions to a .csv file]()\n",
    "- [Decision Trees](#section3)\n",
    "- [Movies Recommendations](#section4)\n",
    "- [Close Spark Session](#section5)\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203ff56-273e-45f0-8f0a-a28e15d5b736",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58941cf-3682-460e-b369-c99bdebe28fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Spark Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa424f-1d70-40ee-870b-816282cee59d",
   "metadata": {},
   "source": [
    "Popular ML libraries for Spark engine are:\n",
    "\n",
    "- mllib\n",
    "- spark-sklearn\n",
    "\n",
    "However, <b>mmlib</b> tends to outperform <b>scikit-learn</b> because it was specifically designed to run on Spark.\n",
    "\n",
    "#### ML Capabilities for mllib:\n",
    "\n",
    "- Feature estraction\n",
    "- Statistics\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Support Vector Machines\n",
    "- Naive Bayes Classifier\n",
    "- Decision Trees\n",
    "- K-Means\n",
    "- PCA\n",
    "- Singular Value Decomposition\n",
    "- Recommendations using Alternating Least Squares\n",
    "\n",
    "\n",
    "#### Summary of use cases:\n",
    "\n",
    "- <b>Predicting values</b>: is a customer going to churn?\n",
    "- <b>Classification</b>: how this document will be classified? / is this a dog or a cat?\n",
    "- <b>Personalized Recommendations</b>: what is the best suitable movie for our audience?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca45b34-13b1-4dbb-92b5-e9fe1e361337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67209509-4722-4dcc-b64b-cd839ae728dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/apavigli/opt/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/23 17:29:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/06/23 17:29:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/06/23 17:29:09 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/06/23 17:29:09 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "23/06/23 17:29:09 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    }
   ],
   "source": [
    "#Create a spark session\n",
    "spark = SparkSession.builder.master('local[*]').appName(\"SparkML\").getOrCreate()\n",
    "\n",
    "def check_spark_version():\n",
    "    #Check version\n",
    "    this_version = spark.version\n",
    "    if int(this_version[0])>=3:\n",
    "        print(f'mmlib deprecated for spark version {this_version}: use new version of MLLib APIs.')\n",
    "    else:\n",
    "        print(f'Spark Version {this_version} allows for old MLLib APIs.')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c57fd8e-42b3-42bf-8eaa-b8fc1652e233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmlib deprecated for spark version 3.2.1: use new version of MLLib APIs.\n"
     ]
    }
   ],
   "source": [
    "check_spark_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1574b75-0f7b-4865-944f-345c02da3b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.80:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkML</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb8931ca4f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d595d68-a1a0-49dd-9fc3-b036629031d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<a id='section2'></a>\n",
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c14e033-bd66-402f-896d-e449e7b68297",
   "metadata": {},
   "source": [
    "<a id='s1p1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2552fb63-ce65-41b8-b793-366f86615072",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53e48490-886e-4018-a264-acd9cff1ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Linear Regression module\n",
    "from pyspark.ml.regression import LinearRegression as spark_LR\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bef792-752e-4633-95fa-e35cbaadacd0",
   "metadata": {},
   "source": [
    "<a id='s1p2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3c31d-cc0a-4d02-affd-707089a2a8f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ML from .txt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b58aa1e0-3fa7-4fa2-940b-ee282a1f9a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regression.csv',\n",
       " 'duplicates.csv',\n",
       " 'regression.txt',\n",
       " 'original.csv',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf9a35d-c49e-48a0-8eed-d0f83b9c4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Target File\n",
    "reg_file = 'input/regression.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0f2f2-7b54-419d-b6f5-3657a3b647ed",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "In PySpark, we use vectors to containerize our features in order to have our predictions.\n",
    "\n",
    "- A <b>vector</b> contains all the features that make the prediction possible. Think of vector as `X` or `X1`\n",
    "- A <b>label</b> is, instead, the value to be bredicted. Think of label as `y`\n",
    "\n",
    "<br>\n",
    "\n",
    "<u>A vector can be either <i>dense</i> or <i>sparse</i>:</u>\n",
    "\n",
    "- it is <b>dense</b> when all variable values are stored, including zeros; \n",
    "- it is <b>sparse</b> when only non-zero variable values are stored, and it is more memory efficient\n",
    "\n",
    "<br>\n",
    "\n",
    "For `pyspark.ml.linalg` we have the `DenseVector` and `SparseVector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84548e29-0dca-41a7-b281-9bdefe74dec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|label|features|\n",
      "+-----+--------+\n",
      "|-1.74|  [1.66]|\n",
      "| 1.24| [-1.18]|\n",
      "| 0.29|  [-0.4]|\n",
      "|-0.13|  [0.09]|\n",
      "|-0.39|  [0.38]|\n",
      "+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Target file\n",
    "inputLines = spark.sparkContext.textFile(reg_file)\n",
    "\n",
    "#Use vectors to convert input lines to usable data and map it to their labels\n",
    "data = inputLines.map(lambda x: x.split(\",\")).map(lambda x: (float(x[0]), Vectors.dense(float(x[1]))))\n",
    "\n",
    "#Create header\n",
    "my_cols = ['label', 'features']\n",
    "\n",
    "#Convert to dataframe\n",
    "df=data.toDF(my_cols)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d87056-f465-4fdf-9468-b4e5f94e63d9",
   "metadata": {},
   "source": [
    "##### Create a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0c4f34-0781-4ef9-b80f-87c28dc45db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe in two subset (80% for training, 20% for testing)\n",
    "trainTest = df.randomSplit([0.8,0.2])\n",
    "df_train = trainTest[0]\n",
    "df_test = trainTest[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc8a33d6-9b74-4111-85f4-3864df4c92f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/23 17:29:19 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/06/23 17:29:19 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# create a model using MMLlib\n",
    "lir = spark_LR(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# fit the model\n",
    "this_model = lir.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a76395a-28d7-49d9-913d-e07cb82ca753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel: uid=LinearRegression_41cf16ac1ba3, numFeatures=1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a21d8b5-0f07-4bc6-b261-18c88894588e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------------------+\n",
      "|label|features|         prediction|\n",
      "+-----+--------+-------------------+\n",
      "|-2.54|  [2.39]| -1.699858778224386|\n",
      "|-2.29|  [2.35]| -1.671264795768647|\n",
      "|-2.26|  [2.25]|   -1.5997798396293|\n",
      "|-2.09|  [1.97]|-1.3996219624391282|\n",
      "|-1.79|  [1.73]|-1.2280580677046953|\n",
      "+-----+--------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate your predictions\n",
    "df_pred = this_model.transform(df_test).cache()\n",
    "\n",
    "df_pred.show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d90efb4-baf6-4749-ad1e-11c986da0643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract prediction values\n",
    "pred = df_pred.select('prediction').rdd.map(lambda  x: x[0])\n",
    "labels = df_pred.select('label').rdd.map(lambda  x: x[0])\n",
    "\n",
    "# zip values together with labels\n",
    "prediction_set = pred.zip(labels).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a1396c0-ab11-41b1-a1a7-5ddeef51fb78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1.699858778224386, -2.54),\n",
       " (-1.671264795768647, -2.29),\n",
       " (-1.5997798396293, -2.26),\n",
       " (-1.3996219624391282, -2.09),\n",
       " (-1.2280580677046953, -1.79)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results (in range 0, 5)\n",
    "prediction_set[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93045e16-847d-4e07-9899-2fc6339c7536",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d0b90-f2ae-417f-9898-ea2df5f436f7",
   "metadata": {},
   "source": [
    "<h3>  </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3bfe9-9e2c-450e-9445-8129566f152d",
   "metadata": {},
   "source": [
    "<a id='s1p3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b60cf3-310e-4900-adc8-1a470643907d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ML from .csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51042110-f373-407c-b60d-938b862009b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|labels|feature1|\n",
      "+------+--------+\n",
      "| -1.74|    1.66|\n",
      "|  1.24|    -1.1|\n",
      "|  0.29|    -0.4|\n",
      "| -0.13|    0.09|\n",
      "| -0.39|    0.38|\n",
      "+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option('header','true').csv('input/regression.csv')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfcc13cd-3113-43fe-9c63-5ee2e3747adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('labels', 'float'), ('feature1', 'float')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the feature columns is float:\n",
    "df = df.withColumn('feature1', df.feature1.cast('float'))\n",
    "\n",
    "# Ensure that `label` is a numerical value as well\n",
    "df = df.withColumn('labels', df.labels.cast('float'))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe26a747-c4bb-405f-9215-8597681e83ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|labels|feature1|\n",
      "+------+--------+\n",
      "| -1.11|    null|\n",
      "| -0.94|    null|\n",
      "| -0.85|    null|\n",
      "| -1.12|    null|\n",
      "| -1.22|    null|\n",
      "| -0.53|    null|\n",
      "| -2.12|    null|\n",
      "| -1.05|    null|\n",
      "| -1.25|    null|\n",
      "|  -0.8|    null|\n",
      "| -0.31|    null|\n",
      "| -0.22|    null|\n",
      "|  -1.2|    null|\n",
      "| -0.33|    null|\n",
      "| -0.82|    null|\n",
      "| -0.09|    null|\n",
      "| -0.68|    null|\n",
      "| -1.34|    null|\n",
      "|  -0.8|    null|\n",
      "|  -0.1|    null|\n",
      "+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check for na\n",
    "df.filter((df.feature1.isNull()) | (df.labels.isNull())).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1489dd1-f11b-4439-a442-458df060bad0",
   "metadata": {},
   "source": [
    "`Null` values are not accepted by MMLlib and they must be handled upfront.\n",
    "\n",
    "For this demonstration we drop Null, however there are several options (using mean, using most frequent value, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8f80aa8-2061-453b-b69b-167d727978a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|labels|feature1|\n",
      "+------+--------+\n",
      "|  0.13|    -0.0|\n",
      "|  0.05|    -0.0|\n",
      "| -0.07|    -0.0|\n",
      "|   0.0|    -0.0|\n",
      "|  0.11|    -0.0|\n",
      "+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check if 0 values are present to decide how to treat Null\n",
    "df.filter(df.feature1 == 0).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "746e8b69-8ce4-4b46-bda4-dca516cc3742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|labels|feature1|\n",
      "+------+--------+\n",
      "| -1.74|    1.66|\n",
      "|  1.24|    -1.1|\n",
      "|  0.29|    -0.4|\n",
      "| -0.13|    0.09|\n",
      "| -0.39|    0.38|\n",
      "+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will drop all null rows\n",
    "df = df.filter(df.feature1.isNotNull())\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bef2f34-8590-4113-b786-4de732f5c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform all features in a single vector column `features`\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vecAssembler = VectorAssembler(inputCols=['feature1'], outputCol=\"features\")\n",
    "df1 = vecAssembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecf20efe-7c6d-4bb6-b1c4-4090fef619a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------------------+\n",
      "|labels|feature1|            features|\n",
      "+------+--------+--------------------+\n",
      "| -1.74|    1.66| [1.659999966621399]|\n",
      "|  1.24|    -1.1|[-1.100000023841858]|\n",
      "|  0.29|    -0.4|[-0.4000000059604...|\n",
      "| -0.13|    0.09|[0.09000000357627...|\n",
      "| -0.39|    0.38|[0.3799999952316284]|\n",
      "+------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a5aa42-5ea5-416b-ad9d-635c3674729b",
   "metadata": {},
   "source": [
    "- The `label` column represents the value to predict\n",
    "- The `features` column is equal to the list of features values for that label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3c438d9-f8bd-4b56-b6c4-1ead125ec586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|-1.74| [1.659999966621399]|\n",
      "| 1.24|[-1.100000023841858]|\n",
      "| 0.29|[-0.4000000059604...|\n",
      "|-0.13|[0.09000000357627...|\n",
      "|-0.39|[0.3799999952316284]|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#prepare dataframe\n",
    "dfx = df1.withColumn('label', df.labels).select('label','features')\n",
    "dfx.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd2fb75b-e1de-4c7d-9c9d-17e219d3fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe in two subset (70% for training, 30% for testing)\n",
    "trainTest_x = dfx.randomSplit([0.7,0.3])\n",
    "dfx_train = trainTest_x[0]\n",
    "dfx_test = trainTest_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a1f4490-3464-404f-95ce-a2788b8404a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: float, features: vector]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d22813c-c779-4f5c-ae54-1c9d87c65479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Linear Regression\n",
    "regression1 = spark_LR(maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc755e8a-c479-446d-ad2b-0815ee2dc420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model_x = regression1.fit(dfx_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5f53e87-4c48-4a62-9ddb-a4e4b14c8f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel: uid=LinearRegression_15e10be9e457, numFeatures=1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1660e2e4-ec4f-4af4-a23d-4aed3f8d4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate your predictions\n",
    "dfx_pred = model_x.transform(dfx_test).cache()\n",
    "\n",
    "# extract prediction values\n",
    "pred_x = dfx_pred.select('prediction').rdd.map(lambda  x: x[0])\n",
    "labels_x = dfx_pred.select('label').rdd.map(lambda  x: x[0])\n",
    "\n",
    "# zip values together with labels\n",
    "prediction_set_x = pred_x.zip(labels_x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3c57de0-40e9-4b70-b96d-564f179eaacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-2.3366550223253086, -3.2300000190734863),\n",
       " (-2.068863216162242, -2.890000104904175),\n",
       " (-1.7069822850932712, -2.5399999618530273),\n",
       " (-1.7793584022837554, -2.5399999618530273),\n",
       " (-1.6707940539397543, -2.430000066757202)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results (in range 0, 5)\n",
    "prediction_set_x[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db25cbe-e7ae-443c-8228-4bf75999390f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce16661-49d0-4317-bec1-d62e092d5bfb",
   "metadata": {},
   "source": [
    "<h3>  </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9431074-00ce-489b-8135-59db8c6f1759",
   "metadata": {},
   "source": [
    "<a id='s1p4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45fb18f-056f-457d-bf96-d8402ed3a814",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572908d7-ea06-4e36-91f6-f941b123ba28",
   "metadata": {},
   "source": [
    "We create a dataframe used the result of our linear regression.\n",
    "\n",
    "Then, we use the values in the dataframe for performance evaluation of the ML model.\n",
    "\n",
    "In this case, we will test Mean Absolute Error (MAE) and Mean Squared Error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6ac1ad6-265d-47ae-92ba-d4f103a6f09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|         prediction|              label|\n",
      "+-------------------+-------------------+\n",
      "|-2.3366550223253086|-3.2300000190734863|\n",
      "| -2.068863216162242| -2.890000104904175|\n",
      "|-1.7069822850932712|-2.5399999618530273|\n",
      "|-1.7793584022837554|-2.5399999618530273|\n",
      "|-1.6707940539397543| -2.430000066757202|\n",
      "+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predschema = StructType([\n",
    "    StructField(\"prediction\", DoubleType(), True),          #predicted value\n",
    "    StructField(\"label\", DoubleType(), True)                #actual value\n",
    "])\n",
    "\n",
    "predf = spark.createDataFrame(prediction_set_x, predschema)\n",
    "predf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee7b0e8c-294a-4ac7-b711-03e78975bdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:\t0.23655989472289898 \n",
      "MSE:\t0.08868880854517451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE and MAE\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Calculate MSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predf)\n",
    "\n",
    "# Then, calculate MAE\n",
    "evaluator.setMetricName(\"mae\")\n",
    "mae = evaluator.evaluate(predf)\n",
    "\n",
    "print(f'MAE:\\t{mae} \\nMSE:\\t{mse}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a0297-a93c-472a-bc6b-a8566b7916b6",
   "metadata": {},
   "source": [
    "<h3>   </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0130fe42-26a1-4e3f-94f0-3abf277ca833",
   "metadata": {},
   "source": [
    "<a id='s1p5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b642f6-4b66-44ea-b697-8f11f8e08bd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save predictions to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae33f2ad-8ec0-47c2-8ca1-f795709c28f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataframe as csv file\n",
    "#try:\n",
    "#    predf.write.csv('output/linear_regression_predictions.csv', encoding='UTF-8')\n",
    "#    print('File saved')\n",
    "#except:\n",
    "#    print('Cannot save. Maybe the file already exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c612f5f8-fb32-42d0-90f9-c74760e99645",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12b2fd96-58bc-468d-aebb-5784a5bbb470",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='section3'></a>\n",
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8598643-5834-41e6-a6c5-38c19c32d806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f236cd1-9f33-4dd8-94b1-7a969998232d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3c73fd9-296e-461f-9eee-f014c7203f8c",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## Movies Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af315e-82bf-49bb-a73f-da16ac98f831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ffd93-414a-459c-a26d-054fe5046109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b7c1a0f-03d5-4c55-93f4-071b5f479e04",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## Close Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f4e9ad6-de3a-4069-9653-9d5f406f572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "795e24af-930d-4442-b013-f3314180321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     End of the Notebook :)\n"
     ]
    }
   ],
   "source": [
    "print('\\n     End of the Notebook :)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
